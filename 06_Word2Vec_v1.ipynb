{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'title', 'tags', 'score', 'answer_count', 'sentence_bow',\n",
      "       'sentence_bow_lem', 'sentence_dl', 'sentence_use'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load train and test datasets\n",
    "df_train = pd.read_csv('stackoverflow_questions_cleaned_train.csv')\n",
    "df_test = pd.read_csv('stackoverflow_questions_cleaned_test.csv')\n",
    "\n",
    "# Print available columns in train dataset\n",
    "print(df_train.columns)\n",
    "\n",
    "# Extract 'sentence_use' column for training and testing\n",
    "X_train_brut = df_train['sentence_bow_lem']\n",
    "X_test_brut = df_test['sentence_bow_lem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load or Train Word2Vec Model and Encode Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anthonydavid/Workspace/Openclassrooms/projet_5\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained Word2Vec model\n",
    "\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 300\n",
    "\n",
    "# Function to encode texts using Word2Vec\n",
    "def encode_texts_w2v(texts, model, vector_size=vector_size):\n",
    "    encoded_texts = []\n",
    "    for text in texts:\n",
    "        tokens = text.split()  # Simple tokenization\n",
    "        vectors = [model[word] for word in tokens if word in model]\n",
    "        if vectors:\n",
    "            encoded_texts.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            encoded_texts.append(np.zeros(vector_size))\n",
    "    return np.array(encoded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Process Tags (same as USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top tags to consider\n",
    "number_of_tags = 50\n",
    "\n",
    "# Create a list of all tags in the training set\n",
    "all_tags = [tag for tags in df_train['tags'].apply(eval) for tag in tags]\n",
    "\n",
    "# Limit tags to the top most frequent\n",
    "top_tags = [tag for tag, count in Counter(all_tags).most_common(number_of_tags)]\n",
    "\n",
    "# Filter tags to keep only the top tags\n",
    "df_train['filtered_tags'] = df_train['tags'].apply(lambda tags: [tag for tag in eval(tags) if tag in top_tags])\n",
    "df_test['filtered_tags'] = df_test['tags'].apply(lambda tags: [tag for tag in eval(tags) if tag in top_tags])\n",
    "\n",
    "# Extract 'sentence_bow_lem' column for training and testing\n",
    "X_train_brut = df_train['sentence_bow_lem']\n",
    "X_test_brut = df_test['sentence_bow_lem']\n",
    "# Encode train and test texts\n",
    "X_train = encode_texts_w2v(X_train_brut, w2v_model)\n",
    "X_test = encode_texts_w2v(X_test_brut, w2v_model)\n",
    "\n",
    "# Filtrer df_train pour ne conserver que les lignes qui ont des tags dans top_tags\n",
    "df_train = df_train[df_train['filtered_tags'].map(len) > 0]\n",
    "\n",
    "# Réencoder les textes pour correspondre aux données filtrées\n",
    "X_train_brut = df_train['sentence_bow_lem']\n",
    "X_train = encode_texts_w2v(X_train_brut, w2v_model)\n",
    "\n",
    "# Ensure the lengths are consistent\n",
    "assert X_train.shape[0] == df_train.shape[0], \"Mismatch in number of training samples after filtering\"\n",
    "\n",
    "# Encode tags with MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=top_tags)\n",
    "y_train = mlb.fit_transform(df_train['filtered_tags'])\n",
    "y_test = mlb.transform(df_test['filtered_tags'])\n",
    "\n",
    "# Ensure the lengths are consistent\n",
    "assert y_train.shape[0] == X_train.shape[0], \"Mismatch in number of training samples after encoding\"\n",
    "assert y_test.shape[0] == X_test.shape[0], \"Mismatch in number of testing samples after encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, number_of_tags, layer_units=[256], activation='relu'):\n",
    "    input_text = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = input_text\n",
    "    for units in layer_units:\n",
    "        x = layers.Dense(units, activation=activation)(x)\n",
    "    \n",
    "    pred = layers.Dense(number_of_tags, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[input_text], outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=[keras.metrics.F1Score(average='micro', threshold=None, name=\"f1_score_micro\", dtype=None),\n",
    "                           keras.metrics.F1Score(average='weighted', threshold=None, name=\"f1_score_weighted\", dtype=None),\n",
    "                           keras.metrics.MeanIoU(num_classes=number_of_tags),\n",
    "                           'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_tags, test_data, test_tags, epochs=10, batch_size=32):\n",
    "    history = model.fit(train_data,\n",
    "                        train_tags,\n",
    "                        validation_data=(test_data, test_tags),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size\n",
    "                        )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Log Model with MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:25:17.107817: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-10-03 21:25:17.108618: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-10-03 21:25:17.108632: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-10-03 21:25:17.108978: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-03 21:25:17.109764: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 21:25:18.779926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.1069 - f1_score_micro: 0.0896 - f1_score_weighted: 0.0377 - loss: 0.2892 - mean_io_u: 0.4856 - val_accuracy: 0.3667 - val_f1_score_micro: 0.1477 - val_f1_score_weighted: 0.0494 - val_loss: 0.1001 - val_mean_io_u: 0.4888\n",
      "Epoch 2/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2254 - f1_score_micro: 0.1865 - f1_score_weighted: 0.0822 - loss: 0.1164 - mean_io_u: 0.4857 - val_accuracy: 0.3672 - val_f1_score_micro: 0.1782 - val_f1_score_weighted: 0.0914 - val_loss: 0.0939 - val_mean_io_u: 0.4888\n",
      "Epoch 3/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.2816 - f1_score_micro: 0.2399 - f1_score_weighted: 0.1489 - loss: 0.1076 - mean_io_u: 0.4856 - val_accuracy: 0.3557 - val_f1_score_micro: 0.2148 - val_f1_score_weighted: 0.1571 - val_loss: 0.0882 - val_mean_io_u: 0.4888\n",
      "Epoch 4/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3149 - f1_score_micro: 0.2811 - f1_score_weighted: 0.2172 - loss: 0.1012 - mean_io_u: 0.4855 - val_accuracy: 0.3697 - val_f1_score_micro: 0.2556 - val_f1_score_weighted: 0.2102 - val_loss: 0.0850 - val_mean_io_u: 0.4888\n",
      "Epoch 5/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.3510 - f1_score_micro: 0.3234 - f1_score_weighted: 0.2627 - loss: 0.0952 - mean_io_u: 0.4854 - val_accuracy: 0.3831 - val_f1_score_micro: 0.2771 - val_f1_score_weighted: 0.2296 - val_loss: 0.0823 - val_mean_io_u: 0.4888\n",
      "Epoch 6/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3689 - f1_score_micro: 0.3500 - f1_score_weighted: 0.2976 - loss: 0.0905 - mean_io_u: 0.4856 - val_accuracy: 0.3896 - val_f1_score_micro: 0.2903 - val_f1_score_weighted: 0.2507 - val_loss: 0.0809 - val_mean_io_u: 0.4892\n",
      "Epoch 7/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.3995 - f1_score_micro: 0.3810 - f1_score_weighted: 0.3331 - loss: 0.0864 - mean_io_u: 0.4856 - val_accuracy: 0.3756 - val_f1_score_micro: 0.3015 - val_f1_score_weighted: 0.2733 - val_loss: 0.0798 - val_mean_io_u: 0.4892\n",
      "Epoch 8/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.3992 - f1_score_micro: 0.3834 - f1_score_weighted: 0.3427 - loss: 0.0852 - mean_io_u: 0.4856 - val_accuracy: 0.3816 - val_f1_score_micro: 0.3137 - val_f1_score_weighted: 0.2852 - val_loss: 0.0786 - val_mean_io_u: 0.4892\n",
      "Epoch 9/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.3939 - f1_score_micro: 0.3891 - f1_score_weighted: 0.3542 - loss: 0.0824 - mean_io_u: 0.4858 - val_accuracy: 0.3418 - val_f1_score_micro: 0.3072 - val_f1_score_weighted: 0.2835 - val_loss: 0.0782 - val_mean_io_u: 0.4892\n",
      "Epoch 10/10\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4091 - f1_score_micro: 0.4069 - f1_score_weighted: 0.3751 - loss: 0.0806 - mean_io_u: 0.4856 - val_accuracy: 0.3597 - val_f1_score_micro: 0.3165 - val_f1_score_weighted: 0.2958 - val_loss: 0.0776 - val_mean_io_u: 0.4892\n"
     ]
    }
   ],
   "source": [
    "layer_units = [256]\n",
    "number_of_layers = len(layer_units)\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "activation = 'relu'\n",
    "\n",
    "\n",
    "# Log the model and results in MLflow\n",
    "mlflow.set_experiment(\"stackoverflow_multilabel_classification\")\n",
    "\n",
    "mlflow.start_run(run_name=\"Word2Vec_model\")\n",
    "description = f\"Training with Word2Vec for multilabel classification with {number_of_layers} dense layers and units {layer_units}\"\n",
    "mlflow.set_tag(\"mlflow.note.content\", description)\n",
    "\n",
    "# Log parameters\n",
    "mlflow.log_param(\"number_of_tags\", number_of_tags)\n",
    "mlflow.log_param(\"embedder\", \"Universal Sentence Encoder\")\n",
    "mlflow.log_param(\"number_of_layers\", number_of_layers)\n",
    "mlflow.log_param(\"units_per_layer\", layer_units)\n",
    "mlflow.log_param(\"activation\", activation)\n",
    "mlflow.log_param(\"output_activation\", 'sigmoid')\n",
    "mlflow.log_param(\"optimizer\", 'adam')\n",
    "mlflow.log_param(\"loss\", 'binary_crossentropy')\n",
    "mlflow.log_param(\"epochs\", epochs)\n",
    "mlflow.log_param(\"batch_size\", batch_size)\n",
    "mlflow.log_param(\"w2v_model\", 'word2vec-google-news-300')\n",
    "mlflow.log_param(\"vector_size\", vector_size)\n",
    "\n",
    "model = create_model(input_shape=(vector_size,), number_of_tags=number_of_tags, layer_units=layer_units)\n",
    "history = train_model(model, X_train, y_train, X_test, y_test, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# # Save model weights\n",
    "model.save_weights('./w2v_model.weights.h5')\n",
    "mlflow.log_artifact('./w2v_model.weights.h5')\n",
    "\n",
    "# mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "for metric, values in history.history.items():\n",
    "    for epoch, value in enumerate(values):\n",
    "        mlflow.log_metric(metric, value, step=epoch)\n",
    "        \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "model.save_weights('./model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Load Model Weights and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Question: How to read a csv file with pandas?\n",
      "Predicted Tags: ('python',)\n",
      "Question: How to read a csv file in python?\n",
      "Predicted Tags: ()\n",
      "Question: What is the best metric for multilabel classification with a neural network?\n",
      "Predicted Tags: ('python',)\n",
      "Question: What is the capital of Paris?\n",
      "Predicted Tags: ()\n"
     ]
    }
   ],
   "source": [
    "# Load the model weights\n",
    "model.load_weights('./model.weights.h5')\n",
    "\n",
    "# New text data for prediction\n",
    "new_text = [\"How to read a csv file with pandas?\",\n",
    "            \"How to read a csv file in python?\",\n",
    "            \"What is the best metric for multilabel classification with a neural network?\", \n",
    "            \"What is the capital of Paris?\"]\n",
    "\n",
    "# Encode new texts using Word2Vec\n",
    "new_text_encoded = encode_texts_w2v(new_text, w2v_model)\n",
    "\n",
    "# Predict\n",
    "predicts = model.predict(new_text_encoded, batch_size=32)\n",
    "\n",
    "# Display predictions\n",
    "threshold = 0.25  # You can adjust this threshold\n",
    "\n",
    "# Get the predicted tags\n",
    "predicted_tags = (predicts > threshold).astype(int)\n",
    "\n",
    "# Transform predicted tags back to the original form\n",
    "predicted_tag_names = mlb.inverse_transform(predicted_tags)\n",
    "\n",
    "for i, text in enumerate(new_text):\n",
    "    print(f\"Question: {text}\")\n",
    "    print(f\"Predicted Tags: {predicted_tag_names[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
