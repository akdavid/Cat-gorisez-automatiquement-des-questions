{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Importer les bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Charger le fichier CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10046 entries, 0 to 10045\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   date              10046 non-null  object\n",
      " 1   title             10046 non-null  object\n",
      " 2   tags              10046 non-null  object\n",
      " 3   score             10046 non-null  int64 \n",
      " 4   answer_count      10046 non-null  int64 \n",
      " 5   sentence_bow      10046 non-null  object\n",
      " 6   sentence_bow_lem  10046 non-null  object\n",
      " 7   sentence_dl       10046 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 628.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>score</th>\n",
       "      <th>answer_count</th>\n",
       "      <th>sentence_bow</th>\n",
       "      <th>sentence_bow_lem</th>\n",
       "      <th>sentence_dl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-16 21:13:48</td>\n",
       "      <td>Is it possible to use to use ssim to find diff...</td>\n",
       "      <td>['python', 'histogram', 'ssim']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>possible use use ssim find differences two ima...</td>\n",
       "      <td>possible use use ssim find difference two imag...</td>\n",
       "      <td>is it possible to use to use ssim to find diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-16 20:54:40</td>\n",
       "      <td>Python: Converting string to integer</td>\n",
       "      <td>['python', 'function', 'integer', 'string-conv...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>python converting string integer</td>\n",
       "      <td>python converting string integer</td>\n",
       "      <td>python converting string to integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-16 20:44:16</td>\n",
       "      <td>How can I get commands in Rails Migration file...</td>\n",
       "      <td>['ruby-on-rails', 'regex', 'ruby', 'migration']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>how get commands rails migration file using regex</td>\n",
       "      <td>how get command rail migration file using regex</td>\n",
       "      <td>how can i get commands in rails migration file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-16 20:43:53</td>\n",
       "      <td>Why do you exclude negative numbers from a max...</td>\n",
       "      <td>['algorithm']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>why exclude negative numbers max path sum algo...</td>\n",
       "      <td>why exclude negative number max path sum algor...</td>\n",
       "      <td>why do you exclude negative numbers from a max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-16 20:37:24</td>\n",
       "      <td>How can I filter an ISODate field based only t...</td>\n",
       "      <td>['mongodb', 'mongodb-query', 'aggregation-fram...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>how filter isodate field based time mongodb</td>\n",
       "      <td>how filter isodate field based time mongodb</td>\n",
       "      <td>how can i filter an isodate field based only t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0  2024-07-16 21:13:48  Is it possible to use to use ssim to find diff...   \n",
       "1  2024-07-16 20:54:40               Python: Converting string to integer   \n",
       "2  2024-07-16 20:44:16  How can I get commands in Rails Migration file...   \n",
       "3  2024-07-16 20:43:53  Why do you exclude negative numbers from a max...   \n",
       "4  2024-07-16 20:37:24  How can I filter an ISODate field based only t...   \n",
       "\n",
       "                                                tags  score  answer_count  \\\n",
       "0                    ['python', 'histogram', 'ssim']      1             1   \n",
       "1  ['python', 'function', 'integer', 'string-conv...      1             2   \n",
       "2    ['ruby-on-rails', 'regex', 'ruby', 'migration']      1             1   \n",
       "3                                      ['algorithm']      2             1   \n",
       "4  ['mongodb', 'mongodb-query', 'aggregation-fram...      2             1   \n",
       "\n",
       "                                        sentence_bow  \\\n",
       "0  possible use use ssim find differences two ima...   \n",
       "1                   python converting string integer   \n",
       "2  how get commands rails migration file using regex   \n",
       "3  why exclude negative numbers max path sum algo...   \n",
       "4        how filter isodate field based time mongodb   \n",
       "\n",
       "                                    sentence_bow_lem  \\\n",
       "0  possible use use ssim find difference two imag...   \n",
       "1                   python converting string integer   \n",
       "2    how get command rail migration file using regex   \n",
       "3  why exclude negative number max path sum algor...   \n",
       "4        how filter isodate field based time mongodb   \n",
       "\n",
       "                                         sentence_dl  \n",
       "0  is it possible to use to use ssim to find diff...  \n",
       "1                python converting string to integer  \n",
       "2  how can i get commands in rails migration file...  \n",
       "3  why do you exclude negative numbers from a max...  \n",
       "4  how can i filter an isodate field based only t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le DataFrame depuis le fichier CSV nettoyé\n",
    "df = pd.read_csv('stackoverflow_questions_cleaned.csv')\n",
    "\n",
    "# Vérifier les données importées\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 3 : Limiter les tags aux 30 plus fréquents et les encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['python' 'javascript' 'c#' 'r' 'c++' 'angular' 'java' 'typescript'\n",
      " 'reactjs' 'html' 'c' 'css' 'android' 'pandas' 'sql' 'excel' 'php'\n",
      " 'dataframe' 'kotlin' 'flutter' 'postgresql' 'swift' 'node.js'\n",
      " 'powershell' '.net' 'django' 'ios' 'android-jetpack-compose' 'go' 'numpy']\n",
      "Tags encodés:\n",
      " [[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Créer une liste de tous les tags\n",
    "all_tags = [tag for tags in df['tags'].apply(eval) for tag in tags]  # Utiliser eval pour convertir les chaînes de listes en listes\n",
    "\n",
    "# Limiter les tags aux 30 plus fréquents\n",
    "top_30_tags = [tag for tag, count in Counter(all_tags).most_common(30)]\n",
    "\n",
    "# Filtrer les tags pour ne garder que les top 30\n",
    "df['filtered_tags'] = df['tags'].apply(lambda tags: [tag for tag in eval(tags) if tag in top_30_tags])\n",
    "\n",
    "# Supprimer les lignes sans tags\n",
    "df = df[df['filtered_tags'].map(len) > 0]\n",
    "\n",
    "# Encoder les tags avec MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=top_30_tags)\n",
    "y = mlb.fit_transform(df['filtered_tags'])\n",
    "\n",
    "# Afficher les tags encodés\n",
    "print(\"Classes:\", mlb.classes_)\n",
    "print(\"Tags encodés:\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4 : Transformer les titres en vecteurs TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de la matrice TF-IDF: (7109, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Utiliser TfidfVectorizer pour encoder les titres\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['sentence_bow'])\n",
    "\n",
    "# Afficher la forme de la matrice TF-IDF\n",
    "print(\"Shape de la matrice TF-IDF:\", X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 5 : Réduire la dimensionnalité des vecteurs TF-IDF avec TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de la matrice réduite: (7109, 1500)\n"
     ]
    }
   ],
   "source": [
    "# Réduire la dimensionnalité des vecteurs TF-IDF\n",
    "svd = TruncatedSVD(n_components=1500)\n",
    "X_reduced = svd.fit_transform(X_tfidf)\n",
    "\n",
    "# Afficher la forme de la matrice réduite\n",
    "print(\"Shape de la matrice réduite:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943866910027216"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_explained = svd.explained_variance_ratio_.sum()\n",
    "var_explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 6 : Entraîner un modèle de classification multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle avec TF-IDF sans réduction dimensionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 (micro): 0.2719703977798335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/16 22:02:14 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle TF-IDF logué dans MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Démarrer une nouvelle run MLflow avec un nom explicite\n",
    "mlflow.start_run(run_name=\"TF-IDF Logistic Regression\")\n",
    "\n",
    "# Entraîner le modèle OneVsRestClassifier avec LogisticRegression\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer et afficher le score F1\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"Score F1 (micro):\", f1)\n",
    "\n",
    "# Loguer les paramètres\n",
    "mlflow.log_param(\"max_features\", 5000)\n",
    "mlflow.log_param(\"test_size\", 0.2)\n",
    "mlflow.log_param(\"model\", \"LogisticRegression - TF-IDF\")\n",
    "\n",
    "# Loguer la métrique\n",
    "mlflow.log_metric(\"f1_score_micro\", f1)\n",
    "\n",
    "# Loguer le modèle sans wrapper\n",
    "mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# Loguer la transformation TF-IDF pour la reproductibilité\n",
    "mlflow.sklearn.log_model(tfidf_vectorizer, \"tfidf_vectorizer\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"Modèle TF-IDF logué dans MLflow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle avec TF-IDF avec réduction dimensionnelle (TruncatedSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score F1 (micro): 0.27821280515891295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/16 22:02:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2024/07/16 22:02:20 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle TF-IDF + SVD logué dans MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Démarrer une nouvelle run MLflow avec un nom explicite\n",
    "mlflow.start_run(run_name=\"TF-IDF + SVD Logistic Regression\")\n",
    "\n",
    "# Entraîner le modèle OneVsRestClassifier avec LogisticRegression\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer et afficher le score F1\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(\"Score F1 (micro):\", f1)\n",
    "\n",
    "# Loguer les paramètres\n",
    "mlflow.log_param(\"max_features\", 5000)\n",
    "mlflow.log_param(\"n_components\", 300)\n",
    "mlflow.log_param(\"test_size\", 0.2)\n",
    "mlflow.log_param(\"model\", \"LogisticRegression - TF-IDF + SVD\")\n",
    "\n",
    "# Loguer la métrique\n",
    "mlflow.log_metric(\"f1_score_micro\", f1)\n",
    "\n",
    "# Loguer le modèle sans wrapper\n",
    "mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# Loguer la transformation TF-IDF et SVD pour la reproductibilité\n",
    "mlflow.sklearn.log_model(tfidf_vectorizer, \"tfidf_vectorizer\")\n",
    "mlflow.sklearn.log_model(svd, \"svd\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"Modèle TF-IDF + SVD logué dans MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédire des tags sur une nouvelle question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags prédits pour la nouvelle question: [('python', 'c#')]\n"
     ]
    }
   ],
   "source": [
    "# Remplacer par l'ID de run de votre modèle logué\n",
    "run_id = \"ec51b67c8da343c58bcdf425f2b4359a\"\n",
    "\n",
    "# Charger le modèle\n",
    "model = mlflow.sklearn.load_model(f\"runs:/{run_id}/model\")\n",
    "\n",
    "# Charger le transformateur TF-IDF\n",
    "tfidf_vectorizer = mlflow.sklearn.load_model(f\"runs:/{run_id}/tfidf_vectorizer\")\n",
    "\n",
    "# Charger le transformateur SVD (si applicable)\n",
    "try:\n",
    "    svd = mlflow.sklearn.load_model(f\"runs:/{run_id}/svd\")\n",
    "except:\n",
    "    svd = None\n",
    "\n",
    "# Exemple de nouvelle question\n",
    "new_question = \"How to use pandas to read a csv file?\"\n",
    "\n",
    "# Transformer la nouvelle question avec TF-IDF\n",
    "X_tfidf_new = tfidf_vectorizer.transform([new_question])\n",
    "\n",
    "# Réduire la dimensionnalité avec SVD si applicable\n",
    "if svd:\n",
    "    X_new = svd.transform(X_tfidf_new)\n",
    "else:\n",
    "    X_new = X_tfidf_new\n",
    "\n",
    "# Prédire les tags pour la nouvelle question\n",
    "predicted_tags = model.predict(X_new)\n",
    "\n",
    "# Utiliser les mêmes tags que ceux utilisés lors de l'entraînement\n",
    "top_30_tags = [tag for tag, count in Counter(all_tags).most_common(30)]\n",
    "mlb = MultiLabelBinarizer(classes=top_30_tags)\n",
    "mlb.fit([top_30_tags])\n",
    "\n",
    "# Interpréter les résultats\n",
    "predicted_tag_names = mlb.inverse_transform(predicted_tags)\n",
    "\n",
    "print(f\"Tags prédits pour la nouvelle question: {predicted_tag_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
